---
title: "Simulation 2 groups"
author: "Thijs Carriere"
date: "13-1-2022"
output: html_document
---

## 0. Libraries and Goals

The goal of this simulation is to find out how MIMIC models can be used to detect differential item functioning and whether DIF can be explained.<br><br>

```{r message=FALSE, warning=FALSE, comment=FALSE}
# load packages 
library(lavaan)
library(tidyverse)

```


## 1. Generating data

For 2 groups ability scores, response scores and response times will be simulated.
The groups will have a difference of 1 in their ability score and 1 item will have uniform DIF, 1 item will have non-uniform DIF. The other items function similar for both groups. 300 observations per group are used

### 1.1 Obtaining Thetas

```{r}
# Making two groups with a difference in theta of 1

# Set seed
set.seed(100)

count.1 <- rnorm(300, -.50, 1)
count.2 <- rnorm(300, .50, 1)

thetas <- as.data.frame(c(count.1, count.2)) # combine them in a frame
colnames(thetas) <- "Theta"

# give them groups (countries)
thetas$group <- 1
thetas[301:600, 2] <- 2


# Generate IDs for observations
thetas$ID <- 1:600
```


### 1.2 Obtaining responses

Generating 6 scores with a 2PL model. Parameters obtained randomly, except for the 5th and 6th item. These items have non-uniform and uniform DIF respectively.<br><br>

On item 5, there is better discrimination for the worse group. On item 6, the item is far easier for the worse group.

```{r Obtaining Responses}
# parameters
set.seed(15)
b_norm <- rnorm(4, 0, 1)
a_norm <- rgamma(4, 1, 1)
a_5 <- c(2, .5)
a_6 <- rgamma(1, 1, 1)
b_5 <- rnorm(1, 0, 1)
b_6 <- c(-.75, .75)

# Get responses
resp <- matrix(NA, nrow = 600, ncol = 6) # create storage
colnames(resp) <- c("item1", "item2", "item3", "item4", "item5", "item6")

# Responses by binomial 2 parameter model for item 1 to item 4
set.seed(113)
for(i in 1:600){
  for(j in 1:4){
    thet <- exp(a_norm[j]*(thetas[i,1] - b_norm[j]))/(1 + exp(a_norm[j]*(thetas[i,1] - b_norm[j])))
    resp[i,j] <- rbinom(1, 1, thet)
  }
}

# Do last 2 items by hand separately to change the item parameters over groups

# item 5
for(i in 1:300){
  thet <- exp(a_5[1]*(thetas[i,1] - b_5))/(1 + exp(a_5[1]*(thetas[i,1] - b_5)))
    resp[i,5] <- rbinom(1, 1, thet)
}

for(i in 301:600){
  thet <- exp(a_5[2]*(thetas[i,1] - b_5))/(1 + exp(a_5[2]*(thetas[i,1] - b_5)))
    resp[i,5] <- rbinom(1, 1, thet)
}


# item 6
for(i in 1:300){
  thet <- exp(a_6*(thetas[i,1] - b_6[1]))/(1 + exp(a_6*(thetas[i,1] - b_6[1])))
    resp[i,6] <- rbinom(1, 1, thet)
}  

for(i in 301:600){
  thet <- exp(a_6*(thetas[i,1] - b_6[2]))/(1 + exp(a_6*(thetas[i,1] - b_6[2])))
    resp[i,6] <- rbinom(1, 1, thet)
} 

```


### 1.3 Generating response times

As process data response times are simulated. For the last item, the second group has average higher response times (40 and 80 seconds). For item 5, the second group is much faster

```{r Response times}
# Add response times, make for 6 a bit different
times <- matrix(NA, 600, 6)
colnames(times) <- c("T1", "T2", "T3", "T4", "T5", "T6")

set.seed(100)
for(i in 1:4){
  mean <- runif(1, 20, 80)
  times[,i] <- rnorm(600, mean, sd = 15)
}

# for question 6, group 2 needs more time than group 1
times[1:300,6] <- rnorm(100, 40, 10)
times[301:600,6] <- rnorm(100, 80, 10)

# for question 5, group 2 needs less time than group 1
times[1:300,5] <- rnorm(100, 80, 10)
times[301:600,5] <- rnorm(100, 40, 10)

```

### 1.4 Combining everything

```{r}
# 1 big frame
data.set <- cbind(thetas, resp, times)
data.set <- data.set %>% select(ID, everything())
data.set$group <- as.factor(data.set$group)

# making dummies
data.set$dum1 <- ifelse(data.set$group == "1", 0, 1)
data.set$dum1 <- as.factor(data.set$dum1)

# right order
data.set <- data.set %>% select(ID, Theta, group, dum1, everything())

# Check data.set
head(data.set)

```

## 2. Simulations 

### 2.1 base model

```{r}
baseline <- '
lat =~ item1 + item2 + item3 + item4 + item5 + item6 
lat ~ dum1
'

# Run model and summary
baseline.mod <- sem(model = baseline, data = data.set, ordered = colnames(data.set[,3:10]) )
summary(baseline.mod, fit.measures = T)
```


### 2.2 Dif model item 6

```{r}
dif6 <- '
lat =~ item1 + item2 + item3 + item4 + item5 + item6 
lat ~ dum1
item6 ~ dum1
'

# Run model and summary
dif6.mod <- sem(model = dif6, data = data.set, ordered = colnames(data.set[,3:10]) )
summary(dif6.mod, fit.measures = T)

# comparte to baseline
anova(baseline.mod, dif6.mod)
```

#### 2.2.1 Comparing to models with 5 items

```{r}
# Set up the same models, now without item 5
baseline2 <- '
lat =~ item1 + item2 + item3 + item4 + item6 
lat ~ dum1
'

dif6_2 <- '
lat =~ item1 + item2 + item3 + item4 + item6 
lat ~ dum1
item6 ~ dum1
'

# Run both models
baseline2.mod <- sem(model = baseline2, data = data.set, ordered = colnames(data.set[,3:10]))
dif6_2.mod <- sem(model = dif6_2, data = data.set, ordered = colnames(data.set[,3:10]))

# Make comparisons
anova(dif6_2.mod, baseline2.mod)

# notice how there is a very good model fit when there is only 1 dif item and you detect the dif with MIMIC. This did not happen before.
```

#### 2.2.2 Explaining DIF in best model

```{r}
# Run new model with response times to explain DIF
expl6 <- '
lat =~ item1 + item2 + item3 + item4 + item6 
lat ~ dum1
T6 ~ dum1
item6 ~ T6
'

expl6.mod <- sem(model = expl6, data = data.set, ordered = colnames(data.set[,3:10]))

summary(expl6.mod)


# Same model, but now with DIF detection included to see difference
expl6_2 <- '
lat =~ item1 + item2 + item3 + item4 + item6 
lat ~ dum1
T6 ~ dum1
item6 ~ T6 + dum1
'

expl6_2.mod <- sem(model = expl6_2, data = data.set, ordered = colnames(data.set[,3:10]))

summary(expl6_2.mod)
summary(dif6_2.mod)
```

### 2.3 DIF model item 5

For the following models, item 6 is deleted and item 5 is returned to see whether MIMIC models detect non-uniform dif.

```{r}
# baseline model to compare with
baseline5<- '
lat =~ item1 + item2 + item3 + item4 + item5 
lat ~ dum1
'

# Model that checks DIF for item 5
dif5 <- '
lat =~ item1 + item2 + item3 + item4 + item5 
lat ~ group
item5 ~ group
'

baseline5.mod <- sem(model = baseline5, data = data.set, ordered = colnames(data.set[,3:10]))

dif5.mod <- sem(model = dif5, data = data.set, ordered = colnames(data.set[,3:10]))

summary(baseline5.mod)
summary(dif5.mod)

```
### 2.4 Inspect item 4 for DIF

To see if no DIF is detected for an item that has no DIF (item 4), MIMIC models are run for item 4.

```{r}
# baseline model to compare with
baseline4<- '
lat =~ item1 + item2 + item3 + item4 
lat ~ dum1
'

# Model that checks DIF for item 5
dif4 <- '
lat =~ item1 + item2 + item3 + item4 
lat ~ group
item4 ~ group
'

baseline4.mod <- sem(model = baseline4, data = data.set, ordered = colnames(data.set[,3:10]))

dif4.mod <- sem(model = dif4, data = data.set, ordered = colnames(data.set[,3:10]))

summary(baseline4.mod)
summary(dif4.mod)
```

This output shows that a model with no DIF items has a good fit (not seen in any of the other models). Therefore, a bad model fit also is a possible indicator for DIF. Also, the b parameter turns out not significant. 

### 2.5 Add an extra DIF item

Now a seventh item is added to the model with both different a and b item-parameters, to see if this item is still detected to have DIF. 

#### 2.5.1 Make item responses

```{r}
# Add new item
resp7 <- matrix(NA, nrow = 600, ncol = 1) 

# Specify item parameters
a7 <- c(2, .5)
b7 <- c(-1, 1)

# obain item responses 
set.seed(100)

for(i in 1:300){
  thet <- exp(a7[1]*(thetas[i,1] - b7[1]))/(1 + exp(a7[1]*(thetas[i,1] - b7[1])))
    resp7[i,1] <- rbinom(1, 1, thet)
}  

for(i in 301:600){
  thet <- exp(a7[2]*(thetas[i,1] - b7[2]))/(1 + exp(a7[2]*(thetas[i,1] - b7[2])))
    resp7[i,1] <- rbinom(1, 1, thet)
}

# Add to dataframe
data.set$item7 <- resp7
data.set <- data.set %>% select(ID:item6, item7, everything())
sum(resp7[1:300])
sum(resp7[301:600])
```

#### 2.5.2 Run models

```{r}
# baseline model to compare with
baseline7<- '
lat =~ item1 + item2 + item3 + item4 + item7 
lat ~ dum1
'

# Model that checks DIF for item 5
dif7 <- '
lat =~ item1 + item2 + item3 + item4 + item7 
lat ~ group
item7 ~ group
'

baseline7.mod <- sem(model = baseline7, data = data.set, ordered = colnames(data.set[,3:11]))

dif7.mod <- sem(model = dif7, data = data.set, ordered = colnames(data.set[,3:11]))

summary(baseline7.mod)
summary(dif7.mod)

```

The baseline model shows a bad fit again, indicating possible DIF. The DIF is then detected in the second model (beta parameter is significant). This could mean that DIF is always detected, but this model can't differentiate between uniform and non-uniform DIF. 

## 3. Conclusions

1. An item with different b values is detected as DIF.
2. An item with different a values is detected as DIF.
3. An item with no different item parameters is NOT detected as DIF.
4. An item with both different a and b values is detected as having DIF.